{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReCap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Welcome to the Tensor2Tensor Colab](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb#scrollTo=oILRLCWN_16u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's transform!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers \n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Для наглядности будем работать с русскоязычной GPT от Сбера.\n",
    "# Ниже команды для загрузки и инициализации модели и токенизатора.\n",
    "model_name_or_path = \"sberbank-ai/rugpt3large_based_on_gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name_or_path).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: 'Сколько будет 2 + 2?'\n",
      "Ответ: '2 + 2 = 4'\n"
     ]
    }
   ],
   "source": [
    "# prompt engineering for QA\n",
    "text = \"Вопрос: 'Сколько будет 2 + 2?'\\nОтвет:\" \n",
    "input_ids = tokenizer.encode(text, return_tensors = \"pt\").to(DEVICE)\n",
    "out = model.generate(input_ids, do_sample = False) \n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: 'Сколько будет два плюс два?'\n",
      "Ответ: 'Два плюс два будет четыре'.\n"
     ]
    }
   ],
   "source": [
    "# prompt engineering for QA\n",
    "text = \"Вопрос: 'Сколько будет два плюс два?'\\nОтвет:\" \n",
    "input_ids = tokenizer.encode(text, return_tensors = \"pt\").to(DEVICE)\n",
    "out = model.generate(input_ids, do_sample = False) \n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "По-русски: 'дом', по-английски: 'house'.\n",
      "\n",
      "— А что\n"
     ]
    }
   ],
   "source": [
    "text = \"По-русски: 'дом', по-английски:\" \n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "out = model.generate(input_ids, do_sample = False) \n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "По-русски: 'машина', по-английски: 'car', по-немецки\n"
     ]
    }
   ],
   "source": [
    "text = \"По-русски: 'машина', по-английски:\" \n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "out = model.generate(input_ids, do_sample = False) \n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "По-русски: 'птица', по-английски: 'bird'.\n",
      "\n",
      "— \n"
     ]
    }
   ],
   "source": [
    "text = \"По-русски: 'птица', по-английски:\" \n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "out = model.generate(input_ids, do_sample = False) \n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Машинное обучение лучше справляется с числами, чем с текстом, поэтому нам необходима процедура токенизации — преобразование текста в последовательность чисел.\n",
    "\n",
    "Самый простой способ сделать это — назначить каждому уникальному слову своё число — токен, а затем заменить все слова в тексте на эти числа. Но есть проблема: слов и их форм очень много (миллионы) и поэтому словарь таких слов - чисел получится чересчур большим, а это будет затруднять обучение модели. Можно разбивать текст не на слова, а на отдельные буквы (char-level tokenization), тогда в словаре будет всего несколько десятков токенов, НО в таком случае уже сам текст после токенизации будет слишком длинным, а это тоже затрудняет обучение.\n",
    "\n",
    "Обычно предпочтительнее выбрать что-то среднее, например, можно разбивать слова на наиболее общие части и представлять их полные версии как комбинации этих кусков (см. картинку). Такой способ токенизации называется BPE (Byte Pair Encoding). Но даже это иногда не самый оптимальный выбор. Чтобы сжать словарь ещё сильнее для обучения GPT OpenAI использовали byte-level BPE токенизацию. Эта модификация BPE работает не с текстом, а напрямую с его байтовым представлением. Использование такого трюка позволило сжать словарь до всего-лишь ~50k токенов при том, что с его помощью всё ещё можно выразить любое слово на любом языке мира (и даже эмодзи)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Токенизируй меня\n",
      "tokens:  [789, 368, 337, 848, 28306, 703]\n",
      "decoded tokens:  ['Т', 'ок', 'ени', 'зи', 'руй', ' меня']\n"
     ]
    }
   ],
   "source": [
    "# Изначальные текст\n",
    "text = \"Токенизируй меня\" \n",
    "# Процесс токенизации с помощьюю токенайзера ruGPT-3\n",
    "tokens = tokenizer.encode(text, add_special_tokens = False) \n",
    "# Обратная поэлементая токенизация\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in tokens] \n",
    "\n",
    "print(\"text:\", text)\n",
    "print(\"tokens: \", tokens)\n",
    "print(\"decoded tokens: \", decoded_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как GPT использует byte-level токенизатор, то не для любого токена найдется существующий символ или слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�\n",
      "�\n",
      "�\n",
      "撝\n"
     ]
    }
   ],
   "source": [
    "# Эти три токена по отдельности не декодируются\n",
    "print(tokenizer.decode([167]))\n",
    "print(tokenizer.decode([245]))\n",
    "print(tokenizer.decode([256]))\n",
    "\n",
    "\n",
    "# Но вместе они образуют иероглиф\n",
    "print(tokenizer.decode([167, 245, 256]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем учить GPT генерировать стихи Пушкина. В качестве обучающих данных возьмём всего лишь один всем известный стих."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddb750b497d4cd4b570799dafb15e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d357537c93e4258b4fa1847b1c1d1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1957e971574d9f879c40e1eabf4d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe522766eac54b49991e249d279263f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/574 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9731f8862eab446e86e1eb80dfdd5c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24afd8a597ec419ca785d2aa43b78eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/551M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_or_path = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name_or_path).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Мороз и солнце; день чудесный!\n",
    "Еще ты дремлешь, друг прелестный —\n",
    "Пора, красавица, проснись:\n",
    "Открой сомкнуты негой взоры\n",
    "Навстречу северной Авроры,\n",
    "Звездою севера явись!\n",
    "Вечор, ты помнишь, вьюга злилась,\n",
    "На мутном небе мгла носилась;\n",
    "Луна, как бледное пятно,\n",
    "Сквозь тучи мрачные желтела,\n",
    "И ты печальная сидела —\n",
    "А нынче... погляди в окно:\n",
    "Под голубыми небесами\n",
    "Великолепными коврами,\n",
    "Блестя на солнце, снег лежит;\n",
    "Прозрачный лес один чернеет,\n",
    "И ель сквозь иней зеленеет,\n",
    "И речка подо льдом блестит.\n",
    "Вся комната янтарным блеском\n",
    "Озарена. Веселым треском\n",
    "Трещит затопленная печь.\n",
    "Приятно думать у лежанки.\n",
    "Но знаешь: не велеть ли в санки\n",
    "Кобылку бурую запречь?\n",
    "Скользя по утреннему снегу,\n",
    "Друг милый, предадимся бегу\n",
    "Нетерпеливого коня\n",
    "И навестим поля пустые,\n",
    "Леса, недавно столь густые,\n",
    "И берег, милый для меня.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "# Сохраним обучающие данные в .txt файл\n",
    "train_path = 'train_dataset.txt'\n",
    "with open(train_path, \"w\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "# Создание датасета\n",
    "train_dataset = TextDataset(tokenizer = tokenizer,file_path = train_path, block_size = 64)\n",
    "\n",
    "# Создание даталодера (нарезает текст на оптимальные по длине куски)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQH4wBW_pN2d"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=200, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=32,  # batch size for evaluation\n",
    "    warmup_steps=10,# number of warmup steps for learning rate scheduler\n",
    "    gradient_accumulation_steps=16, # to make \"virtual\" batch size larger\n",
    "    )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    data_collator = data_collator,\n",
    "    train_dataset = train_dataset,\n",
    "    optimizers = (torch.optim.AdamW(model.parameters(),lr = 1e-5),None) # Optimizer and lr scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "OVtvq4sLq9EG",
    "outputId": "736cc658-8c0f-49f9-94d2-794fe27da8b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 4\n",
      "  Num Epochs = 200\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 512\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:48, Epoch 200/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.03011104345321655, metrics={'train_runtime': 48.7211, 'train_samples_per_second': 16.42, 'train_steps_per_second': 4.105, 'total_flos': 26129203200000.0, 'train_loss': 0.03011104345321655, 'epoch': 200.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_qjIcBUrq0j",
    "outputId": "a80feb81-ec01-4c8d-8449-9690040f8c22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:2259: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Как же сложно учить матанализ!\n",
      "Чтобы в математике успеха добиться,\n",
      "Попробуйте по буквам составить\n",
      "Решение задачи по алгебре.\n",
      "Умножь два на два и реши задачу по геометрии.\n",
      "Умножь на три и реши задачу по алгебре.\n",
      "\n",
      "Что делать если нетбук\n",
      "в сервис\n",
      "Купить новый\n",
      "купить новый. и не заморачиваться с зарядкой\n",
      "купить новый новый\n",
      "Купить новый\n",
      "Купить новый\n"
     ]
    }
   ],
   "source": [
    "# Пример вероятностного сэмплирования с ограничением\n",
    "text = \"Как же сложно учить матанализ!\\n\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids,\n",
    "                        do_sample = True,\n",
    "                        num_beams = 2,\n",
    "                        temperature = 1.5,\n",
    "                        top_p = 0.9,\n",
    "                        max_length = 100,\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izA3-6kffbdT"
   },
   "source": [
    "## Practice: A Visual Notebook to Using BERT for the First Time\n",
    "\n",
    "*Credits: first part of this notebook belongs to Jay Alammar and his [great blog post](http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/) (while it has minor changes). His blog is a great way to dive into the DL and NLP concepts.*\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-sentence-classification.png\" />\n",
    "\n",
    "In this notebook, we will use pre-trained deep learning model to process some text. We will then use the output of that model to classify the text. The text is a list of sentences from film reviews. And we will classify each sentence as either speaking \"positively\" about its subject of \"negatively\".\n",
    "\n",
    "### Models: Sentence Sentiment Classification\n",
    "Our goal is to create a model that takes a sentence (just like the ones in our dataset) and produces either 1 (indicating the sentence carries a positive sentiment) or a 0 (indicating the sentence carries a negative sentiment). We can think of it as looking like this:\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/distilBERT/sentiment-classifier-1.png\" />\n",
    "\n",
    "Under the hood, the model is actually made up of two model.\n",
    "\n",
    "* DistilBERT processes the sentence and passes along some information it extracted from it on to the next model. DistilBERT is a smaller version of BERT developed and open sourced by the team at HuggingFace. It’s a lighter and faster version of BERT that roughly matches its performance.\n",
    "* The next model, a basic Logistic Regression model from scikit learn will take in the result of DistilBERT’s processing, and classify the sentence as either positive or negative (1 or 0, respectively).\n",
    "\n",
    "The data we pass between the two models is a vector of size 768. We can think of this of vector as an embedding for the sentence that we can use for classification.\n",
    "\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/distilBERT/distilbert-bert-sentiment-classifier.png\" />\n",
    "\n",
    "## Dataset\n",
    "The dataset we will use in this example is [SST2](https://nlp.stanford.edu/sentiment/index.html), which contains sentences from movie reviews, each labeled as either positive (has the value 1) or negative (has the value 0):\n",
    "\n",
    "\n",
    "<table class=\"features-table\">\n",
    "  <tr>\n",
    "    <th class=\"mdc-text-light-green-600\">\n",
    "    sentence\n",
    "    </th>\n",
    "    <th class=\"mdc-text-purple-600\">\n",
    "    label\n",
    "    </th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      1\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      apparently reassembled from the cutting room floor of any given daytime soap\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      0\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      they presume their audience won't sit still for a sociology lesson\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      0\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      this is a visually stunning rumination on love , memory , history and the war between art and commerce\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      1\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      jonathan parker 's bartleby should have been the be all end all of the modern office anomie films\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      1\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "## Installing the transformers library\n",
    "Let's start by installing the huggingface transformers library so we can load our deep learning NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "fvFvBLJV0Dkv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQ-42fh0hjsF"
   },
   "source": [
    "## Part 1. Using BERT for text classification.\n",
    "\n",
    "### Importing the dataset\n",
    "We'll use pandas to read the dataset and load it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyoj29J24hPX",
    "outputId": "c7d2f7d9-c661-40a5-f3f1-db5337636e97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 2)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    urlopen('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv'),\n",
    "    delimiter = '\\t',\n",
    "    header = None\n",
    ")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "D8BbWlsdWRu7",
    "outputId": "b407d22d-2653-400c-b639-0512e8cf8992"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "plSYojyFIvBk",
    "outputId": "6d1de215-407b-4117-be34-bf7a54766b08"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a stirring , funny and finally transporting re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apparently reassembled from the cutting room f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they presume their audience wo n't sit still f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a visually stunning rumination on love...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jonathan parker 's bartleby should have been t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  a stirring , funny and finally transporting re...  1\n",
       "1  apparently reassembled from the cutting room f...  0\n",
       "2  they presume their audience wo n't sit still f...  0\n",
       "3  this is a visually stunning rumination on love...  1\n",
       "4  jonathan parker 's bartleby should have been t...  1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMVE3waNhuNj"
   },
   "source": [
    "For performance reasons, we'll only use 2,000 sentences from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "gTM3hOHW4hUY"
   },
   "outputs": [],
   "source": [
    "batch_1 = df[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRc2L89hh1Tf"
   },
   "source": [
    "We can ask pandas how many sentences are labeled as \"positive\" (value 1) and how many are labeled \"negative\" (having the value 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGvcfcCP5xpZ",
    "outputId": "c793e4ea-b8a7-49b0-bd6a-5637c12d8b67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\n",
       "1    1041\n",
       "0     959\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_MO08_KiAOb"
   },
   "source": [
    "## Loading the Pre-trained BERT model\n",
    "Let's now load a pre-trained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219,
     "referenced_widgets": [
      "78255f75ee344f09926e27a6a939c9bb",
      "3baa5f527d304a48be3b58e98e51f1f7",
      "0a7ec24fe3a7460a86eea091c51c9887",
      "79cebbd39fb04274baec99d6cf0499ab",
      "593a80bf49384177aa45bf56a353dd35",
      "a7d568f043b04190b20d2c55fbc50b1b",
      "8cc6a5b109db415a9593608a3e4b9c5c",
      "0ffd2cfea8c9468db0657f6d36629c74",
      "f145ec17fa98497996afc7f69a2fd80b",
      "2cc5c5e0e2c34bd491e0e24513b0886b",
      "1270a336246746519d4f9714b9ac1ccb",
      "bc4f845a09db48a2ae5bbce5d429b498",
      "32b7beff62364a30897e62eda1b3f384",
      "3ff4361cb81a4f4eb27eb79eb1ae3341",
      "31c59a68f5924a758e37eb949ba2f816",
      "5949c9d322b340f69e363ae7c7d37511",
      "882090a4f1824434b8c6cd38c3d4d843",
      "c2766ede6efb434da711a3d411ecc44e",
      "f705ae62e8614bcea0e7752c4acb6bc9",
      "9ed043c8fced41a28db8834a1ad037f7",
      "0429f36e9f214fa488dd1ca4f40bbbf7",
      "4d139c0d764d417c8b5d2e82d88e36ef",
      "adf5ed4d33324d8099f1342a6704874f",
      "5ae3d94180c149148d2bb74a5bdbc38f",
      "eb3fb05e75c747c9b075a3e493a49876",
      "7869fd284ebd40ffb688d0a8d6ac9cb4",
      "c3fc3016724c494c99d39888c5c4eece",
      "489866ae09ae430db5efcc2f4dd9e7f7",
      "899444ca717d46c2b5ebe3b5c3d1dab4",
      "7c5ba3f5ad73403abff626d74666430b",
      "0ce212c7db3b45d395a395060f297941",
      "71639b83156a48bfa0566b935c175175",
      "cb312e12322540638648a9de3c62e0ee",
      "20a2fbba4717420a81e945fda58eaa2c",
      "4e52c5119972494ab8cd3bac817f31b5",
      "5ec7e4d6680347d6bfe05e840cf9d6b4",
      "ebe6d12484f64c67b1c0737e1e5ee22c",
      "92ab1f14a9fc4aa2be0862cdd657acef",
      "8360fda035674baf9ac1fadc021c99f9",
      "186cc30d1f8d44308fc8092ce0d3406a",
      "7cd3b34f20d44af9bd7c4c9536531e34",
      "a561f1d9b7c548c3bf714c501624a42e",
      "2dafd124832d4574ba0f3fdfe5f4cbba",
      "ee3b63b23cfc46cd8032bf43ac05b412"
     ]
    },
    "id": "q1InADgf5xm2",
    "outputId": "1761f45d-9f2f-4084-b672-c255e0d852ae"
   },
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZDBMn3wiSX6"
   },
   "source": [
    "Right now, the variable `model` holds a pretrained distilBERT model -- a version of BERT that is smaller, but much faster and requiring a lot less memory.\n",
    "\n",
    "### Step #1: Preparing the Dataset\n",
    "Before we can hand our sentences to BERT, we need to do some minimal processing to put them in the format it requires.\n",
    "\n",
    "### Tokenization\n",
    "Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "5FtTrZlUPGGX",
    "outputId": "6b3633cf-5737-41c9-be77-6550aabb0b5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a stirring , funny and finally transporting re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apparently reassembled from the cutting room f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  a stirring , funny and finally transporting re...  1\n",
       "1  apparently reassembled from the cutting room f...  0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "Dg82ndBA5xlN"
   },
   "outputs": [],
   "source": [
    "tokenized = batch_1[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ne319RK8EX2k",
    "outputId": "1b0b892a-33de-4615-9301-7df5bae4903a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [101, 1037, 18385, 1010, 6057, 1998, 2633, 182...\n",
       "1       [101, 4593, 2128, 27241, 23931, 2013, 1996, 62...\n",
       "2       [101, 2027, 3653, 23545, 2037, 4378, 24185, 10...\n",
       "3       [101, 2023, 2003, 1037, 17453, 14726, 19379, 1...\n",
       "4       [101, 5655, 6262, 1005, 1055, 12075, 2571, 376...\n",
       "                              ...                        \n",
       "1995    [101, 2205, 20857, 1998, 11865, 16643, 2135, 5...\n",
       "1996    [101, 2009, 2515, 1050, 1005, 1056, 2147, 2004...\n",
       "1997    [101, 2023, 2028, 8704, 2005, 1996, 11848, 199...\n",
       "1998    [101, 1999, 1996, 2171, 1997, 2019, 9382, 1898...\n",
       "1999    [101, 1996, 3185, 2003, 25757, 2011, 1037, 244...\n",
       "Name: 0, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHwjUwYgi-uL"
   },
   "source": [
    "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-tokenization-2-token-ids.png\" />\n",
    "\n",
    "### Padding\n",
    "After tokenization, `tokenized` is a list of sentences -- each sentences is represented as a list of tokens. We want BERT to process our examples all at once (as one batch). It's just faster that way. For that reason, we need to pad all lists to the same size, so we can represent the input as one 2-d array, rather than a list of lists (of different lengths)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "URn-DWJt5xhP"
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxCq-SzQYtc7",
    "outputId": "45db6eb5-b852-45cc-e37b-ee55f10e9b4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       20\n",
       "1       16\n",
       "2       45\n",
       "3       22\n",
       "4       25\n",
       "        ..\n",
       "1995    16\n",
       "1996    10\n",
       "1997    13\n",
       "1998    33\n",
       "1999    31\n",
       "Name: 0, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mdjg306wjjmL"
   },
   "source": [
    "Our dataset is now in the `padded` variable, we can view its dimensions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdi7uXo95xeq",
    "outputId": "49fbe607-b93f-433e-8752-7c5482ff8d50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 59)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDZBsYSDjzDV"
   },
   "source": [
    "### Masking\n",
    "If we directly send `padded` to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xOiNcGbXnMY",
    "outputId": "56de0920-1c5a-486a-a386-ad6ee56c1777"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  1037, 18385, ...,     0,     0,     0],\n",
       "       [  101,  4593,  2128, ...,     0,     0,     0],\n",
       "       [  101,  2027,  3653, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  2023,  2028, ...,     0,     0,     0],\n",
       "       [  101,  1999,  1996, ...,     0,     0,     0],\n",
       "       [  101,  1996,  3185, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4K_iGRNa_Ozc",
    "outputId": "65e23dce-2b0e-404a-d4e6-6ee20fbf897b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 59)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSqMphHcW-Y3",
    "outputId": "31ed50c4-393f-40f2-fd06-65523b7a26c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jK-CQB9-kN99"
   },
   "source": [
    "### Step #1: And Now, Deep Learning!\n",
    "Now that we have our model and inputs ready, let's run our model!\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-tutorial-sentence-embedding.png\" />\n",
    "\n",
    "The `model()` function runs our sentences through BERT. The results of the processing will be returned into `last_hidden_states`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "waCx1DGkQM3m",
    "outputId": "208482d5-2a47-4f78-b458-c8e552457d32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertModel(\n",
      "  (embeddings): Embeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (layer): ModuleList(\n",
      "      (0-5): 6 x TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1037, 18385,  ...,     0,     0,     0],\n",
       "        [  101,  4593,  2128,  ...,     0,     0,     0],\n",
       "        [  101,  2027,  3653,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2023,  2028,  ...,     0,     0,     0],\n",
       "        [  101,  1999,  1996,  ...,     0,     0,     0],\n",
       "        [  101,  1996,  3185,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(padded)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 59])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = torch.tensor(attention_mask)\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 59])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "39UVjAV56PJz"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask = attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[-0.2159, -0.1403,  0.0083,  ..., -0.1369,  0.5867,  0.2011],\n",
       "         [-0.2471,  0.2468,  0.1008,  ..., -0.1631,  0.9349, -0.0715],\n",
       "         [ 0.0558,  0.3573,  0.4140,  ..., -0.2430,  0.1770, -0.5080],\n",
       "         ...,\n",
       "         [-0.0165,  0.1179,  0.3512,  ..., -0.2401,  0.2722, -0.1750],\n",
       "         [ 0.0961,  0.0667,  0.3147,  ..., -0.3277,  0.3556, -0.2135],\n",
       "         [ 0.0454,  0.0519,  0.3168,  ..., -0.2880,  0.1844, -0.1042]],\n",
       "\n",
       "        [[-0.1726, -0.1448,  0.0022,  ..., -0.1744,  0.2139,  0.3720],\n",
       "         [ 0.0022,  0.1684,  0.1269,  ..., -0.1888, -0.0195, -0.0283],\n",
       "         [ 0.0257, -0.2458,  0.0717,  ..., -0.4339,  0.1622,  0.0133],\n",
       "         ...,\n",
       "         [ 0.0505, -0.0493,  0.0463,  ..., -0.0448, -0.0540,  0.3136],\n",
       "         [-0.2128, -0.1907, -0.0215,  ...,  0.0139, -0.2433, -0.0202],\n",
       "         [-0.1310, -0.1693,  0.1019,  ..., -0.0859, -0.1770, -0.0872]],\n",
       "\n",
       "        [[-0.0506,  0.0720, -0.0296,  ..., -0.0715,  0.7185,  0.2623],\n",
       "         [ 0.0536,  0.3136, -0.0598,  ...,  0.2676,  0.8668, -0.3380],\n",
       "         [ 0.3792,  0.2792,  0.0237,  ...,  0.0343,  0.4272,  0.1680],\n",
       "         ...,\n",
       "         [ 0.2314,  0.2427,  0.1030,  ..., -0.0840,  0.2322,  0.0613],\n",
       "         [ 0.0741,  0.0465,  0.1083,  ...,  0.0530,  0.1971,  0.0233],\n",
       "         [ 0.1042,  0.3139,  0.0768,  ..., -0.0301,  0.1052, -0.0780]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.2783, -0.2480,  0.1359,  ..., -0.1904,  0.1310,  0.3498],\n",
       "         [-0.4406, -0.5159,  0.1700,  ..., -0.3430,  0.3747,  0.0846],\n",
       "         [-0.4604, -0.3928,  0.0390,  ..., -0.3068, -0.1666,  0.2803],\n",
       "         ...,\n",
       "         [-0.2033, -0.2213,  0.2879,  ..., -0.2334, -0.1342,  0.1061],\n",
       "         [-0.0998, -0.2407,  0.1394,  ..., -0.1828, -0.0762,  0.2031],\n",
       "         [-0.0663, -0.1063,  0.1606,  ..., -0.2004, -0.2571,  0.1438]],\n",
       "\n",
       "        [[-0.0367,  0.1064, -0.0111,  ..., -0.1121,  0.4162,  0.5034],\n",
       "         [-0.1869,  0.3485, -0.8375,  ..., -0.1169,  0.3985,  0.3065],\n",
       "         [-0.3108,  0.2174, -0.1678,  ..., -0.1267,  0.3512, -0.0812],\n",
       "         ...,\n",
       "         [ 0.0874,  0.0203,  0.0381,  ...,  0.1545,  0.0125,  0.1109],\n",
       "         [ 0.2528, -0.0149,  0.0847,  ...,  0.0441,  0.1973,  0.2889],\n",
       "         [ 0.2378, -0.0568,  0.2862,  ...,  0.0842,  0.1540,  0.1655]],\n",
       "\n",
       "        [[ 0.1240,  0.0143,  0.0104,  ..., -0.1161,  0.5346,  0.2750],\n",
       "         [ 0.1294, -0.2348, -0.0882,  ...,  0.0997,  1.1743, -0.3309],\n",
       "         [ 0.5874, -0.1074, -0.0561,  ..., -0.0401,  0.3627, -0.4122],\n",
       "         ...,\n",
       "         [ 0.4066, -0.1452,  0.0651,  ...,  0.0879,  0.3980, -0.1256],\n",
       "         [ 0.4385, -0.1488,  0.1139,  ..., -0.0744,  0.3416, -0.3278],\n",
       "         [ 0.5451, -0.0851,  0.1311,  ..., -0.0017,  0.3413, -0.3513]]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoCep_WVuB3v"
   },
   "source": [
    "Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called `[CLS]` (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/distilBERT/bert-output-tensor-selection.png\" />\n",
    "\n",
    "We'll save those in the `features` variable, as they'll serve as the features to our logitics regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "e0d_9tD-JkV8"
   },
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8skxFymLZsJz",
    "outputId": "425dc142-c8a6-4145-c7a2-ac697b898090"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 768)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21593425, -0.1402892 ,  0.00831067, ..., -0.13694862,\n",
       "         0.5867011 ,  0.20112711],\n",
       "       [-0.17262734, -0.14476168,  0.00223432, ..., -0.17442551,\n",
       "         0.21386452,  0.37197483],\n",
       "       [-0.05063391,  0.07203969, -0.02959736, ..., -0.07148959,\n",
       "         0.7185237 ,  0.26225442],\n",
       "       ...,\n",
       "       [-0.27829766, -0.24803624,  0.13585773, ..., -0.1903916 ,\n",
       "         0.1309958 ,  0.34978363],\n",
       "       [-0.03667699,  0.10638555, -0.01110996, ..., -0.11206629,\n",
       "         0.41619474,  0.5033803 ],\n",
       "       [ 0.12402657,  0.01425149,  0.01038393, ..., -0.11606539,\n",
       "         0.53459173,  0.2749534 ]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2oTu-6uyqQC",
    "outputId": "4540566b-29b4-4f9c-c867-b9ef7335529d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 59])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pfnZOK-dyqQD",
    "outputId": "9fdd85ce-d054-4927-ae2c-e5ab3ad31ce7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 59, 768])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0r_rBskW4uk",
    "outputId": "24ffa503-c95b-4b94-9935-f9e9734c81d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[-0.2159, -0.1403,  0.0083,  ..., -0.1369,  0.5867,  0.2011],\n",
       "         [-0.2471,  0.2468,  0.1008,  ..., -0.1631,  0.9349, -0.0715],\n",
       "         [ 0.0558,  0.3573,  0.4140,  ..., -0.2430,  0.1770, -0.5080],\n",
       "         ...,\n",
       "         [-0.0165,  0.1179,  0.3512,  ..., -0.2401,  0.2722, -0.1750],\n",
       "         [ 0.0961,  0.0667,  0.3147,  ..., -0.3277,  0.3556, -0.2135],\n",
       "         [ 0.0454,  0.0519,  0.3168,  ..., -0.2880,  0.1844, -0.1042]],\n",
       "\n",
       "        [[-0.1726, -0.1448,  0.0022,  ..., -0.1744,  0.2139,  0.3720],\n",
       "         [ 0.0022,  0.1684,  0.1269,  ..., -0.1888, -0.0195, -0.0283],\n",
       "         [ 0.0257, -0.2458,  0.0717,  ..., -0.4339,  0.1622,  0.0133],\n",
       "         ...,\n",
       "         [ 0.0505, -0.0493,  0.0463,  ..., -0.0448, -0.0540,  0.3136],\n",
       "         [-0.2128, -0.1907, -0.0215,  ...,  0.0139, -0.2433, -0.0202],\n",
       "         [-0.1310, -0.1693,  0.1019,  ..., -0.0859, -0.1770, -0.0872]],\n",
       "\n",
       "        [[-0.0506,  0.0720, -0.0296,  ..., -0.0715,  0.7185,  0.2623],\n",
       "         [ 0.0536,  0.3136, -0.0598,  ...,  0.2676,  0.8668, -0.3380],\n",
       "         [ 0.3792,  0.2792,  0.0237,  ...,  0.0343,  0.4272,  0.1680],\n",
       "         ...,\n",
       "         [ 0.2314,  0.2427,  0.1030,  ..., -0.0840,  0.2322,  0.0613],\n",
       "         [ 0.0741,  0.0465,  0.1083,  ...,  0.0530,  0.1971,  0.0233],\n",
       "         [ 0.1042,  0.3139,  0.0768,  ..., -0.0301,  0.1052, -0.0780]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.2783, -0.2480,  0.1359,  ..., -0.1904,  0.1310,  0.3498],\n",
       "         [-0.4406, -0.5159,  0.1700,  ..., -0.3430,  0.3747,  0.0846],\n",
       "         [-0.4604, -0.3928,  0.0390,  ..., -0.3068, -0.1666,  0.2803],\n",
       "         ...,\n",
       "         [-0.2033, -0.2213,  0.2879,  ..., -0.2334, -0.1342,  0.1061],\n",
       "         [-0.0998, -0.2407,  0.1394,  ..., -0.1828, -0.0762,  0.2031],\n",
       "         [-0.0663, -0.1063,  0.1606,  ..., -0.2004, -0.2571,  0.1438]],\n",
       "\n",
       "        [[-0.0367,  0.1064, -0.0111,  ..., -0.1121,  0.4162,  0.5034],\n",
       "         [-0.1869,  0.3485, -0.8375,  ..., -0.1169,  0.3985,  0.3065],\n",
       "         [-0.3108,  0.2174, -0.1678,  ..., -0.1267,  0.3512, -0.0812],\n",
       "         ...,\n",
       "         [ 0.0874,  0.0203,  0.0381,  ...,  0.1545,  0.0125,  0.1109],\n",
       "         [ 0.2528, -0.0149,  0.0847,  ...,  0.0441,  0.1973,  0.2889],\n",
       "         [ 0.2378, -0.0568,  0.2862,  ...,  0.0842,  0.1540,  0.1655]],\n",
       "\n",
       "        [[ 0.1240,  0.0143,  0.0104,  ..., -0.1161,  0.5346,  0.2750],\n",
       "         [ 0.1294, -0.2348, -0.0882,  ...,  0.0997,  1.1743, -0.3309],\n",
       "         [ 0.5874, -0.1074, -0.0561,  ..., -0.0401,  0.3627, -0.4122],\n",
       "         ...,\n",
       "         [ 0.4066, -0.1452,  0.0651,  ...,  0.0879,  0.3980, -0.1256],\n",
       "         [ 0.4385, -0.1488,  0.1139,  ..., -0.0744,  0.3416, -0.3278],\n",
       "         [ 0.5451, -0.0851,  0.1311,  ..., -0.0017,  0.3413, -0.3513]]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VZVU66Gurr-"
   },
   "source": [
    "The labels indicating which sentence is positive and negative now go into the `labels` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "JD3fX2yh6PTx"
   },
   "outputs": [],
   "source": [
    "labels = batch_1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaoEvM2evRx1"
   },
   "source": [
    "### Step #3: Train/Test Split\n",
    "Let's now split our datset into a training set and testing set (even though we're using 2,000 sentences from the SST2 training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "ddAqbkoU6PP9"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9bhSJpcv1Bl"
   },
   "source": [
    "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-train-test-split-sentence-embedding.png\" />\n",
    "\n",
    "### [Extra] Grid Search for Parameters\n",
    "We can dive into Logistic regression directly with the Scikit Learn default parameters, but sometimes it's worth searching for the best value of the C parameter, which determines regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyEwr7yYD3Ci",
    "outputId": "83edda16-201d-4b00-c61e-c7f8f349f4d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 5.263252631578947}\n",
      "best scrores:  0.806\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
    "grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "print('best parameters: ', grid_search.best_params_)\n",
    "print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCT9u8vAwnID"
   },
   "source": [
    "We now train the LogisticRegression model. If you've chosen to do the gridsearch, you can plug the value of C into the model declaration (e.g. `LogisticRegression(C=5.2)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gG-EVWx4CzBc",
    "outputId": "d022922a-54cb-49c3-d762-74e987955400"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=5.263252631578947)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=5.263252631578947)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=5.263252631578947)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=grid_search.best_params_['C'])\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rUMKuVgwzkY"
   },
   "source": [
    "<img src=\"https://jalammar.github.io/images/distilBERT/bert-training-logistic-regression.png\" />\n",
    "\n",
    "### Step #4:  Evaluating Model\n",
    "So how well does our model do in classifying sentences? One way is to check the accuracy against the testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iCoyxRJ7ECTA",
    "outputId": "5027ed84-2123-45c6-8978-0a57848c83f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.846"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75oyhr3VxHoE"
   },
   "source": [
    "How good is this score? What can we compare it against? Let's first look at a dummy classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LttGVKY0KaYU",
    "outputId": "45149cbb-2646-4ac8-de17-951e8768aa26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 768)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lnwgmqNG7i5l",
    "outputId": "d005dcd4-6078-459a-ce59-7fbb2a23e614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier score: 0.523 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, train_features, train_labels)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Lg4LOpoxSOR"
   },
   "source": [
    "So our model clearly does better than a dummy classifier. But how does it compare against the best models?\n",
    "\n",
    "### Proper SST2 scores\n",
    "For reference, the [highest accuracy score](http://nlpprogress.com/english/sentiment_analysis.html) for this dataset is currently **96.8**. DistilBERT can be trained to improve its score on this task – a process called **fine-tuning** which updates BERT’s weights to make it achieve a better performance in this sentence classification task (which we can call the downstream task). The fine-tuned DistilBERT turns out to achieve an accuracy score of **90.7**. The full size BERT model achieves **94.9**.\n",
    "\n",
    "\n",
    "\n",
    "And that’s it! That’s a good first contact with BERT. The next step would be to head over to the documentation and try your hand at [fine-tuning](https://huggingface.co/transformers/examples.html#glue). You can also go back and switch from distilBERT to BERT and see how that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3LmkzSSKHEv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0429f36e9f214fa488dd1ca4f40bbbf7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a7ec24fe3a7460a86eea091c51c9887": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ffd2cfea8c9468db0657f6d36629c74",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f145ec17fa98497996afc7f69a2fd80b",
      "value": 231508
     }
    },
    "0ce212c7db3b45d395a395060f297941": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0ffd2cfea8c9468db0657f6d36629c74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1270a336246746519d4f9714b9ac1ccb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "186cc30d1f8d44308fc8092ce0d3406a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20a2fbba4717420a81e945fda58eaa2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e52c5119972494ab8cd3bac817f31b5",
       "IPY_MODEL_5ec7e4d6680347d6bfe05e840cf9d6b4",
       "IPY_MODEL_ebe6d12484f64c67b1c0737e1e5ee22c"
      ],
      "layout": "IPY_MODEL_92ab1f14a9fc4aa2be0862cdd657acef"
     }
    },
    "2cc5c5e0e2c34bd491e0e24513b0886b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dafd124832d4574ba0f3fdfe5f4cbba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31c59a68f5924a758e37eb949ba2f816": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0429f36e9f214fa488dd1ca4f40bbbf7",
      "placeholder": "​",
      "style": "IPY_MODEL_4d139c0d764d417c8b5d2e82d88e36ef",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.80kB/s]"
     }
    },
    "32b7beff62364a30897e62eda1b3f384": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_882090a4f1824434b8c6cd38c3d4d843",
      "placeholder": "​",
      "style": "IPY_MODEL_c2766ede6efb434da711a3d411ecc44e",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "3baa5f527d304a48be3b58e98e51f1f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7d568f043b04190b20d2c55fbc50b1b",
      "placeholder": "​",
      "style": "IPY_MODEL_8cc6a5b109db415a9593608a3e4b9c5c",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "3ff4361cb81a4f4eb27eb79eb1ae3341": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f705ae62e8614bcea0e7752c4acb6bc9",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ed043c8fced41a28db8834a1ad037f7",
      "value": 28
     }
    },
    "489866ae09ae430db5efcc2f4dd9e7f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d139c0d764d417c8b5d2e82d88e36ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e52c5119972494ab8cd3bac817f31b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8360fda035674baf9ac1fadc021c99f9",
      "placeholder": "​",
      "style": "IPY_MODEL_186cc30d1f8d44308fc8092ce0d3406a",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "593a80bf49384177aa45bf56a353dd35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5949c9d322b340f69e363ae7c7d37511": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ae3d94180c149148d2bb74a5bdbc38f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_489866ae09ae430db5efcc2f4dd9e7f7",
      "placeholder": "​",
      "style": "IPY_MODEL_899444ca717d46c2b5ebe3b5c3d1dab4",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "5ec7e4d6680347d6bfe05e840cf9d6b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cd3b34f20d44af9bd7c4c9536531e34",
      "max": 267954768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a561f1d9b7c548c3bf714c501624a42e",
      "value": 267954768
     }
    },
    "71639b83156a48bfa0566b935c175175": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78255f75ee344f09926e27a6a939c9bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3baa5f527d304a48be3b58e98e51f1f7",
       "IPY_MODEL_0a7ec24fe3a7460a86eea091c51c9887",
       "IPY_MODEL_79cebbd39fb04274baec99d6cf0499ab"
      ],
      "layout": "IPY_MODEL_593a80bf49384177aa45bf56a353dd35"
     }
    },
    "7869fd284ebd40ffb688d0a8d6ac9cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71639b83156a48bfa0566b935c175175",
      "placeholder": "​",
      "style": "IPY_MODEL_cb312e12322540638648a9de3c62e0ee",
      "value": " 483/483 [00:00&lt;00:00, 40.2kB/s]"
     }
    },
    "79cebbd39fb04274baec99d6cf0499ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cc5c5e0e2c34bd491e0e24513b0886b",
      "placeholder": "​",
      "style": "IPY_MODEL_1270a336246746519d4f9714b9ac1ccb",
      "value": " 232k/232k [00:00&lt;00:00, 4.99MB/s]"
     }
    },
    "7c5ba3f5ad73403abff626d74666430b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cd3b34f20d44af9bd7c4c9536531e34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8360fda035674baf9ac1fadc021c99f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "882090a4f1824434b8c6cd38c3d4d843": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "899444ca717d46c2b5ebe3b5c3d1dab4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8cc6a5b109db415a9593608a3e4b9c5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92ab1f14a9fc4aa2be0862cdd657acef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ed043c8fced41a28db8834a1ad037f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a561f1d9b7c548c3bf714c501624a42e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a7d568f043b04190b20d2c55fbc50b1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adf5ed4d33324d8099f1342a6704874f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5ae3d94180c149148d2bb74a5bdbc38f",
       "IPY_MODEL_eb3fb05e75c747c9b075a3e493a49876",
       "IPY_MODEL_7869fd284ebd40ffb688d0a8d6ac9cb4"
      ],
      "layout": "IPY_MODEL_c3fc3016724c494c99d39888c5c4eece"
     }
    },
    "bc4f845a09db48a2ae5bbce5d429b498": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_32b7beff62364a30897e62eda1b3f384",
       "IPY_MODEL_3ff4361cb81a4f4eb27eb79eb1ae3341",
       "IPY_MODEL_31c59a68f5924a758e37eb949ba2f816"
      ],
      "layout": "IPY_MODEL_5949c9d322b340f69e363ae7c7d37511"
     }
    },
    "c2766ede6efb434da711a3d411ecc44e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3fc3016724c494c99d39888c5c4eece": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb312e12322540638648a9de3c62e0ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb3fb05e75c747c9b075a3e493a49876": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c5ba3f5ad73403abff626d74666430b",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ce212c7db3b45d395a395060f297941",
      "value": 483
     }
    },
    "ebe6d12484f64c67b1c0737e1e5ee22c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dafd124832d4574ba0f3fdfe5f4cbba",
      "placeholder": "​",
      "style": "IPY_MODEL_ee3b63b23cfc46cd8032bf43ac05b412",
      "value": " 268M/268M [00:01&lt;00:00, 222MB/s]"
     }
    },
    "ee3b63b23cfc46cd8032bf43ac05b412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f145ec17fa98497996afc7f69a2fd80b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f705ae62e8614bcea0e7752c4acb6bc9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
